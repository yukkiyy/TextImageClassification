{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS480_Kaggle_RoBERTa.ipynb","provenance":[{"file_id":"1zmWAIpzJjaPZ0excxVsE4CXdZsn-aXac","timestamp":1607141896356}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MISs6c_Dq_ev"},"source":["Execution Instruction:\r\n","\r\n","*   Environment: Colab\r\n","*   Data: Kaggle\r\n"]},{"cell_type":"code","metadata":{"id":"GngQuKV8h3dL"},"source":["!rm -rf *.csv\n","!rm -rf suffled-images\n","!rm -rf uw-cs480-fall20.zip\n","!rm -rf sample_data\n","!rm -rf *.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWfuIQbJin6S","executionInfo":{"status":"ok","timestamp":1607237500465,"user_tz":300,"elapsed":6141,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"a5909e87-8165-4f44-c375-cc40e2ecce7a"},"source":["!pip install -q transformers\n","!pip install xgboost"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dpwjn_j498e6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607237500466,"user_tz":300,"elapsed":6134,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"4a99ff75-9d30-4b19-be05-8180735057a7"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dDQM0GJL4a5G","executionInfo":{"status":"ok","timestamp":1607237500467,"user_tz":300,"elapsed":6124,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"4ea3dcd0-2418-4050-c901-eddb6ea274cf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","DRIVE_PATH='/content/drive/My Drive/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eORlGh5dvdSW","executionInfo":{"status":"ok","timestamp":1607237503733,"user_tz":300,"elapsed":9378,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"0a0f9718-9107-49cd-d204-b69bd5686cae"},"source":["import os\n","\n","os.environ['KAGGLE_USERNAME'] = \"yukkiy\"\n","os.environ['KAGGLE_KEY'] = \"f57ccfa218c9719dd46d9401bb8bffc4\"\n","\n","import kaggle\n","\n","kaggle.api.authenticate()\n","kaggle.api.competition_download_files(\"uw-cs480-fall20\", path='.', quiet=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0.00/85.6M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading uw-cs480-fall20.zip to .\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 85.6M/85.6M [00:02<00:00, 34.3MB/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6gCGgHcii1pq"},"source":["import time\n","\n","import numpy as np\n","import pandas as pd \n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","from tensorflow.keras.layers import Input, Dropout, Dense, Concatenate, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model, Sequential, load_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras import regularizers\n","\n","from tensorflow.keras.applications.vgg19 import preprocess_input, VGG19\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","\n","from transformers import RobertaConfig, TFRobertaModel, RobertaTokenizerFast\n","\n","import xgboost as xgb\n","import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICycxJQLiBOR","executionInfo":{"status":"ok","timestamp":1607237508764,"user_tz":300,"elapsed":14394,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"ad49dcf8-a035-4b7c-dbd1-15bdc19f3e6c"},"source":["!unzip -q uw-cs480-fall20.zip -d .\n","%ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/                 \u001b[01;34msuffled-images\u001b[0m/  train.csv\n","sample_submission.csv  test.csv         uw-cs480-fall20.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0upb1UGaiF1c"},"source":["INPUT_PATH = '/content/'\n","INPUT_IMAGE_PATH = '/content/suffled-images/shuffled-images/'\n","\n","data_size = 21627\n","train_size = 19224\n","test_size = 2403\n","\n","batch_size = 32\n","num_epochs = 50\n","image_shape = (80, 60, 3)\n","\n","num_training_vgg = 5\n","\n","predict_size = 21628\n","\n","description_model_name = 'roberta-large'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDl4QRp6ikzm"},"source":["dataframe = pd.read_csv(INPUT_PATH + 'train.csv', header=0)\n","dataframe_predict = pd.read_csv(INPUT_PATH + 'test.csv', header=0)\n","data = dataframe.values.copy()\n","data_predict = dataframe_predict.values.copy()\n","\n","data_image_id = data[:, 0]\n","data_category = data[:, 1]\n","data_feature = data[:, [2, 3, 4, 5]]\n","data_description = data[:, 6]\n","\n","predict_image_id = data_predict[:, 0]\n","predict_feature = data_predict[:, [1, 2, 3, 4]]\n","predict_description = data_predict[:, 5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VX_U6C_yn9Df"},"source":["shuffle_indices = np.arange(data_size)\n","np.random.shuffle(shuffle_indices)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T64zQidGjYVk"},"source":["# image processing\n","\n","data_image = np.zeros(shape=(data_size, image_shape[0], image_shape[1], image_shape[2]))\n","\n","for i in range(data_size):\n","    id = data_image_id[i]\n","    img = load_img(INPUT_IMAGE_PATH + str(id) +'.jpg')\n","    img = img_to_array(img)\n","    img = preprocess_input(img)\n","    data_image[i] = img\n","\n","data_image = data_image[shuffle_indices]\n","\n","train_image = data_image[: train_size]\n","test_image = data_image[train_size :]\n","\n","\n","# # This will do preprocessing and realtime data augmentation:\n","# image_datagen = ImageDataGenerator(\n","#     featurewise_center=False,  # set input mean to 0 over the dataset\n","#     samplewise_center=False,  # set each sample mean to 0\n","#     featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","#     samplewise_std_normalization=False,  # divide each input by its std\n","#     zca_whitening=False,  # apply ZCA whitening\n","#     zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","#     rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","#     # randomly shift images horizontally (fraction of total width)\n","#     width_shift_range=0.1,\n","#     # randomly shift images vertically (fraction of total height)\n","#     height_shift_range=0.1,\n","#     shear_range=0.,  # set range for random shear\n","#     zoom_range=0.,  # set range for random zoom\n","#     channel_shift_range=0.,  # set range for random channel shifts\n","#     # set mode for filling points outside the input boundaries\n","#     fill_mode='nearest',\n","#     cval=0.,  # value used for fill_mode = \"constant\"\n","#     horizontal_flip=True,  # randomly flip images\n","#     vertical_flip=False,  # randomly flip images\n","#     # set rescaling factor (applied before any other transformation)\n","#     rescale=None,\n","#     # set function that will be applied on each input\n","#     preprocessing_function=None,\n","#     # image data format, either \"channels_first\" or \"channels_last\"\n","#     data_format=None,\n","#     # fraction of images reserved for validation (strictly between 0 and 1)\n","#     validation_split=0.0)\n","\n","# # Compute quantities required for feature-wise normalization\n","# # (std, mean, and principal components if ZCA whitening is applied).\n","# image_datagen.fit(train_image)\n","\n","\n","predict_image = np.zeros(shape=(predict_size, image_shape[0], image_shape[1], image_shape[2]))\n","\n","for i in range(predict_size):\n","    id = predict_image_id[i]\n","    img = load_img(INPUT_IMAGE_PATH + str(id) +'.jpg')\n","    img = img_to_array(img)\n","    img = preprocess_input(img)\n","    predict_image[i] = img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRQsVljqjtLK"},"source":["# description processing\n","\n","data_description_feature = np.empty(shape=data_description.shape, dtype=data_description.dtype)\n","\n","def string_combine(str1, str2, str3, str4, str5):\n","    return str1 + ' ' + str2 + ' ' + str3 + ' ' + str4 + ' ' + str5\n","\n","for i in range(data_size):\n","    data_description_feature[i] = string_combine(data_description[i], \n","                                                 data_feature[i][0], \n","                                                 data_feature[i][1], \n","                                                 data_feature[i][2], \n","                                                 data_feature[i][3])\n","\n","data_description_feature = data_description_feature[shuffle_indices]\n","train_description_feature = data_description_feature[: train_size]\n","test_description_feature = data_description_feature[train_size :]\n","\n","\n","predict_description_feature = np.empty(shape=predict_description.shape, dtype=predict_description.dtype)\n","\n","for i in range(predict_size):\n","    predict_description_feature[i] = string_combine(predict_description[i], \n","                                                    predict_feature[i][0], \n","                                                    predict_feature[i][1], \n","                                                    predict_feature[i][2], \n","                                                    predict_feature[i][3])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ud9hl4nznILg"},"source":["description_maxlength = 1\n","\n","# max length of tokens\n","for description in np.concatenate((data_description_feature, predict_description_feature)):\n","    description_maxlength = max(description_maxlength, len(description))\n","\n","# load transformers config and set output_hidden_states to False\n","roberta_config = RobertaConfig.from_pretrained(description_model_name)\n","roberta_config.output_hidden_states = False\n","\n","#load RoBERTa tokenizer\n","roberta_tokenizer = RobertaTokenizerFast.from_pretrained(pretrained_model_name_or_path = description_model_name, config = roberta_config)\n","\n","\n","train_description_feature_token = roberta_tokenizer(\n","    text=train_description_feature.tolist(),\n","    add_special_tokens=True,\n","    max_length=description_maxlength,\n","    truncation=True,\n","    padding=True, \n","    return_tensors='tf',\n","    return_token_type_ids = False,\n","    return_attention_mask = False,\n","    verbose = 1)\n","\n","test_description_feature_token = roberta_tokenizer(\n","    text=test_description_feature.tolist(),\n","    add_special_tokens=True,\n","    max_length=description_maxlength,\n","    truncation=True,\n","    padding=True, \n","    return_tensors='tf',\n","    return_token_type_ids = False,\n","    return_attention_mask = False,\n","    verbose = 1)\n","\n","predict_description_feature_token = roberta_tokenizer(\n","    text=predict_description_feature.tolist(),\n","    add_special_tokens=True,\n","    max_length=description_maxlength,\n","    truncation=True,\n","    padding=True, \n","    return_tensors='tf',\n","    return_token_type_ids = False,\n","    return_attention_mask = False,\n","    verbose = 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u29dqkRDlZGE"},"source":["# category processing\n","\n","categories = np.unique(data_category)\n","num_category = categories.shape[0]\n","\n","code_to_categ = {}\n","categ_to_code = {}\n","\n","for code in range(num_category):\n","    code_to_categ[code] = categories[code]\n","    categ_to_code[categories[code]] = code\n","\n","data_category_code = np.zeros(shape=data_category.shape)\n","\n","for i in range(data_size):\n","    data_category_code[i] = categ_to_code[data_category[i]]\n","\n","data_category_code_categorical = to_categorical(data_category_code, num_category)\n","\n","\n","data_category_code_categorical = data_category_code_categorical[shuffle_indices]\n","train_category_code_categorical = data_category_code_categorical[: train_size]\n","test_category_code_categorical = data_category_code_categorical[train_size :]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzHmO-0vouwh"},"source":["# define image model\n","\n","vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_shape=image_shape, pooling='max', classes=num_category)\n","for layer in vgg19.layers[: -1 * num_training_vgg]:\n","    layer.trainable = False\n","\n","image_layers_output = vgg19.output\n","image_layers_output = Dense(1024, activation='relu')(image_layers_output)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ue19PeDbrRAa","executionInfo":{"status":"ok","timestamp":1607237540807,"user_tz":300,"elapsed":46358,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"cef2df14-bad3-4001-aaf2-09ced2c6ae9f"},"source":["# define description model\n","\n","token_maxlength = max(train_description_feature_token['input_ids'].shape[1], test_description_feature_token['input_ids'].shape[1])\n","token_maxlength = max(token_maxlength, predict_description_feature_token['input_ids'].shape[1])\n","\n","# load the transformres RoBERTa model\n","transformer_model = TFRobertaModel.from_pretrained(description_model_name, config = roberta_config)\n","\n","# Load the MainLayer\n","roberta = transformer_model.layers[0]\n","\n","# Build your model input\n","input_ids = Input(shape=(token_maxlength,), name='input_ids', dtype='int32')\n","# attention_mask = Input(shape=(token_maxlength), name='attention_mask', dtype='int32')\n","description_inputs = {'input_ids': input_ids}\n","\n","# Load the Transformers RoBERTa model as a layer in a Keras model\n","description_layers_output = roberta(description_inputs)[1]\n","roberta_dropout = Dropout(roberta_config.hidden_dropout_prob, name=\"pooled_output\")\n","description_layers_output = roberta_dropout(description_layers_output, training=False)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8OfgZjk8sZ1j"},"source":["# define ensemble model\n","\n","ensemble = Concatenate(axis=1)([image_layers_output, description_layers_output])\n","ensemble = Dropout(0.1)(ensemble)\n","ensemble = Dense(512, activation='relu')(ensemble)\n","ensemble = Dropout(0.2)(ensemble)\n","ensemble_predictions = Dense(num_category, activation='softmax')(ensemble)\n","\n","ensemble_model = Model(inputs=[vgg19.input, description_inputs], outputs=[ensemble_predictions])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxfvPMQ6tTZe","executionInfo":{"status":"ok","timestamp":1607237540811,"user_tz":300,"elapsed":46346,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"48bff394-d8e4-4996-a4d9-4db8a5ddc8af"},"source":["opt_ensemble = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6)\n","\n","ensemble_model.compile(loss='categorical_crossentropy',\n","              optimizer=opt_ensemble,\n","              metrics=['accuracy'])\n","\n","print(ensemble_model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 80, 60, 3)]  0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 80, 60, 64)   1792        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 80, 60, 64)   36928       block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, 40, 30, 64)   0           block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block2_conv1 (Conv2D)           (None, 40, 30, 128)  73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","block2_conv2 (Conv2D)           (None, 40, 30, 128)  147584      block2_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 20, 15, 128)  0           block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv1 (Conv2D)           (None, 20, 15, 256)  295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","block3_conv2 (Conv2D)           (None, 20, 15, 256)  590080      block3_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv3 (Conv2D)           (None, 20, 15, 256)  590080      block3_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv4 (Conv2D)           (None, 20, 15, 256)  590080      block3_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 10, 7, 256)   0           block3_conv4[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv1 (Conv2D)           (None, 10, 7, 512)   1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","block4_conv2 (Conv2D)           (None, 10, 7, 512)   2359808     block4_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv3 (Conv2D)           (None, 10, 7, 512)   2359808     block4_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv4 (Conv2D)           (None, 10, 7, 512)   2359808     block4_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 5, 3, 512)    0           block4_conv4[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv1 (Conv2D)           (None, 5, 3, 512)    2359808     block4_pool[0][0]                \n","__________________________________________________________________________________________________\n","block5_conv2 (Conv2D)           (None, 5, 3, 512)    2359808     block5_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv3 (Conv2D)           (None, 5, 3, 512)    2359808     block5_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv4 (Conv2D)           (None, 5, 3, 512)    2359808     block5_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block5_pool (MaxPooling2D)      (None, 2, 1, 512)    0           block5_conv4[0][0]               \n","__________________________________________________________________________________________________\n","input_ids (InputLayer)          [(None, 49)]         0                                            \n","__________________________________________________________________________________________________\n","global_max_pooling2d (GlobalMax (None, 512)          0           block5_pool[0][0]                \n","__________________________________________________________________________________________________\n","roberta (TFRobertaMainLayer)    TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1024)         525312      global_max_pooling2d[0][0]       \n","__________________________________________________________________________________________________\n","pooled_output (Dropout)         (None, 1024)         0           roberta[0][1]                    \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 2048)         0           dense[0][0]                      \n","                                                                 pooled_output[0][0]              \n","__________________________________________________________________________________________________\n","dropout_73 (Dropout)            (None, 2048)         0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 512)          1049088     dropout_73[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_74 (Dropout)            (None, 512)          0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 27)           13851       dropout_74[0][0]                 \n","==================================================================================================\n","Total params: 376,972,379\n","Trainable params: 364,027,419\n","Non-trainable params: 12,944,960\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9Wj9W6itifQ","executionInfo":{"status":"ok","timestamp":1607254116047,"user_tz":300,"elapsed":16621569,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"22b92f45-d07b-4a7b-9379-f3dd178795fa"},"source":["\n","save_best_model_ensemble = ModelCheckpoint('best_model_ensemble.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n","\n","class TimeHistory(keras.callbacks.Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","\n","    def on_epoch_begin(self, batch, logs={}):\n","        self.epoch_time_start = time.time()\n","\n","    def on_epoch_end(self, batch, logs={}):\n","        self.times.append(time.time() - self.epoch_time_start)\n","        print(self.times[-1], ' seconds')\n","\n","time_callback = TimeHistory()\n","\n","\n","history_ensemble = ensemble_model.fit([train_image, train_description_feature_token['input_ids']], train_category_code_categorical, \n","                                            batch_size=batch_size,\n","                                            epochs=num_epochs, \n","                                            validation_data=([test_image, test_description_feature_token['input_ids']], test_category_code_categorical),\n","                                            shuffle=True,\n","                                            callbacks=[save_best_model_ensemble, time_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","WARNING:tensorflow:Model was constructed with shape (None, 49) for input Tensor(\"input_ids:0\", shape=(None, 49), dtype=int32), but it was called on an input with incompatible shape (None, 39).\n","WARNING:tensorflow:Model was constructed with shape (None, 49) for input Tensor(\"input_ids:0\", shape=(None, 49), dtype=int32), but it was called on an input with incompatible shape (None, 39).\n","601/601 [==============================] - ETA: 0s - loss: 1.3744 - accuracy: 0.6788WARNING:tensorflow:Model was constructed with shape (None, 49) for input Tensor(\"input_ids:0\", shape=(None, 49), dtype=int32), but it was called on an input with incompatible shape (None, 41).\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.92593, saving model to best_model_ensemble.h5\n","399.23959136009216  seconds\n","601/601 [==============================] - 370s 615ms/step - loss: 1.3744 - accuracy: 0.6788 - val_loss: 0.3392 - val_accuracy: 0.9259\n","Epoch 2/50\n","601/601 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.9297\n","Epoch 00002: val_accuracy improved from 0.92593 to 0.94632, saving model to best_model_ensemble.h5\n","365.76877450942993  seconds\n","601/601 [==============================] - 365s 608ms/step - loss: 0.2895 - accuracy: 0.9297 - val_loss: 0.1869 - val_accuracy: 0.9463\n","Epoch 3/50\n","601/601 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.9557\n","Epoch 00003: val_accuracy improved from 0.94632 to 0.96338, saving model to best_model_ensemble.h5\n","364.2916979789734  seconds\n","601/601 [==============================] - 364s 605ms/step - loss: 0.1735 - accuracy: 0.9557 - val_loss: 0.1492 - val_accuracy: 0.9634\n","Epoch 4/50\n","601/601 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9670\n","Epoch 00004: val_accuracy improved from 0.96338 to 0.96380, saving model to best_model_ensemble.h5\n","362.10033774375916  seconds\n","601/601 [==============================] - 362s 602ms/step - loss: 0.1256 - accuracy: 0.9670 - val_loss: 0.1445 - val_accuracy: 0.9638\n","Epoch 5/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9759\n","Epoch 00005: val_accuracy improved from 0.96380 to 0.96837, saving model to best_model_ensemble.h5\n","361.6538944244385  seconds\n","601/601 [==============================] - 361s 601ms/step - loss: 0.0919 - accuracy: 0.9759 - val_loss: 0.1412 - val_accuracy: 0.9684\n","Epoch 6/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9831\n","Epoch 00006: val_accuracy improved from 0.96837 to 0.96921, saving model to best_model_ensemble.h5\n","363.7310562133789  seconds\n","601/601 [==============================] - 363s 604ms/step - loss: 0.0648 - accuracy: 0.9831 - val_loss: 0.1293 - val_accuracy: 0.9692\n","Epoch 7/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9848\n","Epoch 00007: val_accuracy did not improve from 0.96921\n","322.7287018299103  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0552 - accuracy: 0.9848 - val_loss: 0.1389 - val_accuracy: 0.9642\n","Epoch 8/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9913\n","Epoch 00008: val_accuracy improved from 0.96921 to 0.97212, saving model to best_model_ensemble.h5\n","365.1515426635742  seconds\n","601/601 [==============================] - 365s 607ms/step - loss: 0.0350 - accuracy: 0.9913 - val_loss: 0.1295 - val_accuracy: 0.9721\n","Epoch 9/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9918\n","Epoch 00009: val_accuracy did not improve from 0.97212\n","322.29473781585693  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0291 - accuracy: 0.9918 - val_loss: 0.1418 - val_accuracy: 0.9709\n","Epoch 10/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9942\n","Epoch 00010: val_accuracy did not improve from 0.97212\n","322.18074893951416  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.1406 - val_accuracy: 0.9713\n","Epoch 11/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9940\n","Epoch 00011: val_accuracy did not improve from 0.97212\n","322.2634696960449  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.1464 - val_accuracy: 0.9696\n","Epoch 12/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9958\n","Epoch 00012: val_accuracy did not improve from 0.97212\n","322.14989852905273  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.1784 - val_accuracy: 0.9663\n","Epoch 13/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9954\n","Epoch 00013: val_accuracy did not improve from 0.97212\n","322.1176896095276  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.1490 - val_accuracy: 0.9721\n","Epoch 14/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9965\n","Epoch 00014: val_accuracy did not improve from 0.97212\n","322.1033685207367  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.1508 - val_accuracy: 0.9721\n","Epoch 15/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9962\n","Epoch 00015: val_accuracy did not improve from 0.97212\n","322.2448318004608  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.1847 - val_accuracy: 0.9675\n","Epoch 16/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9975\n","Epoch 00016: val_accuracy did not improve from 0.97212\n","322.09847140312195  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1946 - val_accuracy: 0.9713\n","Epoch 17/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9976\n","Epoch 00017: val_accuracy improved from 0.97212 to 0.97503, saving model to best_model_ensemble.h5\n","365.23564314842224  seconds\n","601/601 [==============================] - 365s 607ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.1575 - val_accuracy: 0.9750\n","Epoch 18/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9966\n","Epoch 00018: val_accuracy did not improve from 0.97503\n","322.44375467300415  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1767 - val_accuracy: 0.9730\n","Epoch 19/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9963\n","Epoch 00019: val_accuracy did not improve from 0.97503\n","322.5326645374298  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.1997 - val_accuracy: 0.9680\n","Epoch 20/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9977\n","Epoch 00020: val_accuracy did not improve from 0.97503\n","322.4041612148285  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1909 - val_accuracy: 0.9709\n","Epoch 21/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9976\n","Epoch 00021: val_accuracy did not improve from 0.97503\n","322.3960061073303  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1835 - val_accuracy: 0.9725\n","Epoch 22/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9984\n","Epoch 00022: val_accuracy did not improve from 0.97503\n","322.3102831840515  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.1821 - val_accuracy: 0.9717\n","Epoch 23/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9971\n","Epoch 00023: val_accuracy improved from 0.97503 to 0.97628, saving model to best_model_ensemble.h5\n","364.3864243030548  seconds\n","601/601 [==============================] - 364s 605ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.1761 - val_accuracy: 0.9763\n","Epoch 24/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9996\n","Epoch 00024: val_accuracy did not improve from 0.97628\n","322.2354643344879  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1914 - val_accuracy: 0.9713\n","Epoch 25/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9973\n","Epoch 00025: val_accuracy did not improve from 0.97628\n","322.6140034198761  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.1906 - val_accuracy: 0.9725\n","Epoch 26/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9981\n","Epoch 00026: val_accuracy did not improve from 0.97628\n","322.3973994255066  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.1760 - val_accuracy: 0.9734\n","Epoch 27/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9969\n","Epoch 00027: val_accuracy did not improve from 0.97628\n","322.23509883880615  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1757 - val_accuracy: 0.9750\n","Epoch 28/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9978\n","Epoch 00028: val_accuracy did not improve from 0.97628\n","322.1677234172821  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.1855 - val_accuracy: 0.9750\n","Epoch 29/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 00029: val_accuracy did not improve from 0.97628\n","322.10693430900574  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1784 - val_accuracy: 0.9725\n","Epoch 30/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9995\n","Epoch 00030: val_accuracy did not improve from 0.97628\n","322.4096510410309  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2060 - val_accuracy: 0.9684\n","Epoch 31/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9972\n","Epoch 00031: val_accuracy did not improve from 0.97628\n","322.5554141998291  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.1831 - val_accuracy: 0.9746\n","Epoch 32/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n","Epoch 00032: val_accuracy did not improve from 0.97628\n","322.526579618454  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.2004 - val_accuracy: 0.9742\n","Epoch 33/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n","Epoch 00033: val_accuracy did not improve from 0.97628\n","322.2991952896118  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1995 - val_accuracy: 0.9746\n","Epoch 34/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9747\n","Epoch 00034: val_accuracy did not improve from 0.97628\n","322.2836983203888  seconds\n","601/601 [==============================] - 322s 535ms/step - loss: 0.0923 - accuracy: 0.9747 - val_loss: 0.5625 - val_accuracy: 0.8764\n","Epoch 35/50\n","601/601 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.9033\n","Epoch 00035: val_accuracy did not improve from 0.97628\n","322.6921637058258  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.3293 - accuracy: 0.9033 - val_loss: 0.4378 - val_accuracy: 0.8926\n","Epoch 36/50\n","601/601 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.9383\n","Epoch 00036: val_accuracy did not improve from 0.97628\n","322.6069447994232  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.2008 - accuracy: 0.9383 - val_loss: 0.3762 - val_accuracy: 0.9060\n","Epoch 37/50\n","601/601 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9642\n","Epoch 00037: val_accuracy did not improve from 0.97628\n","322.80621337890625  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.1118 - accuracy: 0.9642 - val_loss: 0.1708 - val_accuracy: 0.9746\n","Epoch 38/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n","Epoch 00038: val_accuracy did not improve from 0.97628\n","322.795170545578  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1788 - val_accuracy: 0.9738\n","Epoch 39/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994\n","Epoch 00039: val_accuracy did not improve from 0.97628\n","322.55792593955994  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1722 - val_accuracy: 0.9746\n","Epoch 40/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9996\n","Epoch 00040: val_accuracy did not improve from 0.97628\n","322.7676839828491  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1584 - val_accuracy: 0.9759\n","Epoch 41/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997\n","Epoch 00041: val_accuracy did not improve from 0.97628\n","322.5475811958313  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1665 - val_accuracy: 0.9763\n","Epoch 42/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 00042: val_accuracy improved from 0.97628 to 0.97961, saving model to best_model_ensemble.h5\n","364.24467182159424  seconds\n","601/601 [==============================] - 364s 605ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1597 - val_accuracy: 0.9796\n","Epoch 43/50\n","601/601 [==============================] - ETA: 0s - loss: 2.5579e-04 - accuracy: 0.9999\n","Epoch 00043: val_accuracy did not improve from 0.97961\n","322.79625415802  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 2.5579e-04 - accuracy: 0.9999 - val_loss: 0.1594 - val_accuracy: 0.9784\n","Epoch 44/50\n","601/601 [==============================] - ETA: 0s - loss: 7.5665e-04 - accuracy: 0.9999\n","Epoch 00044: val_accuracy did not improve from 0.97961\n","322.54759097099304  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 7.5665e-04 - accuracy: 0.9999 - val_loss: 0.1655 - val_accuracy: 0.9784\n","Epoch 45/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n","Epoch 00045: val_accuracy did not improve from 0.97961\n","322.69525384902954  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.2044 - val_accuracy: 0.9742\n","Epoch 46/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9951\n","Epoch 00046: val_accuracy did not improve from 0.97961\n","322.5602581501007  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.1637 - val_accuracy: 0.9763\n","Epoch 47/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n","Epoch 00047: val_accuracy did not improve from 0.97961\n","322.7089054584503  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1852 - val_accuracy: 0.9750\n","Epoch 48/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n","Epoch 00048: val_accuracy did not improve from 0.97961\n","323.0019783973694  seconds\n","601/601 [==============================] - 322s 537ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1984 - val_accuracy: 0.9746\n","Epoch 49/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n","Epoch 00049: val_accuracy did not improve from 0.97961\n","322.77519273757935  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1801 - val_accuracy: 0.9771\n","Epoch 50/50\n","601/601 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 00050: val_accuracy did not improve from 0.97961\n","322.7454435825348  seconds\n","601/601 [==============================] - 322s 536ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1945 - val_accuracy: 0.9763\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"LguSp4YHus3O","executionInfo":{"status":"ok","timestamp":1607254116050,"user_tz":300,"elapsed":16621559,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"32466ae6-43d6-448e-ccb8-69d6d458929a"},"source":["plt.plot(history_ensemble.history['accuracy'], label='train')\n","plt.plot(history_ensemble.history['val_accuracy'], label='validate')\n","plt.title('accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(loc='lower right')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"XMdUKy1Fuy4T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607254302241,"user_tz":300,"elapsed":16807743,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"029cfb27-d3d9-4fc4-935c-01438b6b057a"},"source":["saved_model = load_model('best_model_ensemble.h5')\n","predicted_category_ensemble = saved_model.predict([predict_image, predict_description_feature_token['input_ids']], batch_size=batch_size, verbose=1)\n","predicted_category_code = np.argmax(predicted_category_ensemble, axis=-1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["676/676 [==============================] - 150s 222ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8SOrPCgzu04V"},"source":["predicted_category = np.empty(shape=predict_size, dtype=data_category.dtype)\n","\n","for i in range(predict_size):\n","    predicted_category[i] = code_to_categ[predicted_category_code[i]]\n","\n","submission = np.concatenate((predict_image_id.reshape((predict_size, 1)), predicted_category.reshape((predict_size, 1))), axis=1)\n","np.savetxt(DRIVE_PATH + 'submission_ensemble.csv', submission, fmt='%d,%s', header='id,category', comments='')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtITAvUm4f1b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607254308420,"user_tz":300,"elapsed":16813910,"user":{"displayName":"Yukki Y","photoUrl":"","userId":"00121684746442032188"}},"outputId":"3d0be682-ae51-416d-fae1-4e46c0a581ba"},"source":["drive.flush_and_unmount()\n","print('All changes made in this colab session should now be visible in Drive.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["All changes made in this colab session should now be visible in Drive.\n"],"name":"stdout"}]}]}